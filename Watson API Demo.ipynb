{
    "metadata": {
        "language_info": {
            "version": "3.5.2", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }, 
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "name": "python", 
            "pygments_lexer": "ipython3"
        }, 
        "kernelspec": {
            "display_name": "Python 3.5 (Experimental) with Spark 2.0", 
            "language": "python", 
            "name": "python3-spark20"
        }
    }, 
    "nbformat": 4, 
    "cells": [
        {
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "markdown", 
            "source": "# Watson Conversation API Testing Framework\nThis notebook demonstrates a simple framework for training and testing IBM Watson Conversation API \nBy managing the training process programmatically, the intent recognition performance can be reliably tested with a truly blind test set."
        }, 
        {
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Requirement already up-to-date: watson-developer-cloud in /gpfs/global_fs01/sym_shared/YPProdSpark/user/sa7d-9dd5fbf856b6db-aa3b21eda791/.local/lib/python3.5/site-packages\nRequirement already up-to-date: pysolr<4.0,>=3.3 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/sa7d-9dd5fbf856b6db-aa3b21eda791/.local/lib/python3.5/site-packages (from watson-developer-cloud)\nRequirement already up-to-date: requests<3.0,>=2.0 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/sa7d-9dd5fbf856b6db-aa3b21eda791/.local/lib/python3.5/site-packages (from watson-developer-cloud)\nRequirement already up-to-date: pyOpenSSL>=16.2.0 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/sa7d-9dd5fbf856b6db-aa3b21eda791/.local/lib/python3.5/site-packages (from watson-developer-cloud)\nRequirement already up-to-date: urllib3<1.23,>=1.21.1 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/sa7d-9dd5fbf856b6db-aa3b21eda791/.local/lib/python3.5/site-packages (from requests<3.0,>=2.0->watson-developer-cloud)\nRequirement already up-to-date: chardet<3.1.0,>=3.0.2 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/sa7d-9dd5fbf856b6db-aa3b21eda791/.local/lib/python3.5/site-packages (from requests<3.0,>=2.0->watson-developer-cloud)\nRequirement already up-to-date: certifi>=2017.4.17 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/sa7d-9dd5fbf856b6db-aa3b21eda791/.local/lib/python3.5/site-packages (from requests<3.0,>=2.0->watson-developer-cloud)\nRequirement already up-to-date: idna<2.7,>=2.5 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/sa7d-9dd5fbf856b6db-aa3b21eda791/.local/lib/python3.5/site-packages (from requests<3.0,>=2.0->watson-developer-cloud)\nRequirement already up-to-date: six>=1.5.2 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/sa7d-9dd5fbf856b6db-aa3b21eda791/.local/lib/python3.5/site-packages (from pyOpenSSL>=16.2.0->watson-developer-cloud)\nRequirement already up-to-date: cryptography>=1.9 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/sa7d-9dd5fbf856b6db-aa3b21eda791/.local/lib/python3.5/site-packages (from pyOpenSSL>=16.2.0->watson-developer-cloud)\nRequirement already up-to-date: asn1crypto>=0.21.0 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/sa7d-9dd5fbf856b6db-aa3b21eda791/.local/lib/python3.5/site-packages (from cryptography>=1.9->pyOpenSSL>=16.2.0->watson-developer-cloud)\nCollecting cffi>=1.7 (from cryptography>=1.9->pyOpenSSL>=16.2.0->watson-developer-cloud)\n  Downloading cffi-1.11.1-cp35-cp35m-manylinux1_x86_64.whl (419kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 419kB 2.2MB/s eta 0:00:01\n\u001b[?25hRequirement already up-to-date: pycparser in /gpfs/global_fs01/sym_shared/YPProdSpark/user/sa7d-9dd5fbf856b6db-aa3b21eda791/.local/lib/python3.5/site-packages (from cffi>=1.7->cryptography>=1.9->pyOpenSSL>=16.2.0->watson-developer-cloud)\nInstalling collected packages: cffi\n  Found existing installation: cffi 1.11.0\n    Uninstalling cffi-1.11.0:\n      Successfully uninstalled cffi-1.11.0\nSuccessfully installed cffi-1.11.1\n", 
                    "name": "stdout"
                }
            ], 
            "cell_type": "code", 
            "execution_count": 1, 
            "source": "# install watson-developer-cloud library\n!pip install --upgrade watson-developer-cloud"
        }, 
        {
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Requirement already up-to-date: sklearn in /gpfs/global_fs01/sym_shared/YPProdSpark/user/sa7d-9dd5fbf856b6db-aa3b21eda791/.local/lib/python3.5/site-packages\nRequirement already up-to-date: scikit-learn in /gpfs/global_fs01/sym_shared/YPProdSpark/user/sa7d-9dd5fbf856b6db-aa3b21eda791/.local/lib/python3.5/site-packages (from sklearn)\n", 
                    "name": "stdout"
                }
            ], 
            "cell_type": "code", 
            "execution_count": 2, 
            "source": "# install sklearn (aka SciKit-Learn)\n!pip install sklearn --upgrade"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 3, 
            "source": "# import prerequisite libraries\nimport pandas as pd\nimport numpy as np\nfrom bokeh.charts import Histogram, output_file, show\nimport random\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split"
        }, 
        {
            "metadata": {}, 
            "outputs": [
                {
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "execution_count": 5, 
                    "data": {
                        "text/plain": "                               example        intent\n0              you can say what is php  capabilities\n1         you can not change yourself?  capabilities\n2                 why should I use you  capabilities\n3                  where should I turn  capabilities\n4  where is the poop deck on this ship  capabilities", 
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>example</th>\n      <th>intent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>you can say what is php</td>\n      <td>capabilities</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>you can not change yourself?</td>\n      <td>capabilities</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>why should I use you</td>\n      <td>capabilities</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>where should I turn</td>\n      <td>capabilities</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>where is the poop deck on this ship</td>\n      <td>capabilities</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    }
                }
            ], 
            "cell_type": "code", 
            "execution_count": 5, 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 6, 
            "source": "# store into variable df\ntry:\n    df = df_data_1\nexcept NameError as e:\n    print('Error: Setup is incorrect or incomplete.\\n')\n    print('Follow the instructions to insert the pandas DataFrame above, and edit to')\n    print('make the generated df_data_# variable match the variable used here.')\n    raise"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 7, 
            "source": "# split data into training and test sets\n# typically training data is 80%. However, we should investigate this and confirm leading practices\ntrain, test = train_test_split(df, test_size = 0.2)"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 8, 
            "source": "# supply workspace and authentication parameters\nCONVERSATION_USERNAME = '6a6ab898-dea9-423c-baf1-bd6e87ee5dc3'\nCONVERSATION_PASSWORD = 'Lb7eIkjJI5Bb'\nVERSION = '2017-05-26'\nWORKSPACE_ID = 'b1f9955f-c7db-4298-90fe-c98a65735832'"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 9, 
            "source": "# create the authtication json object\nimport json\nfrom watson_developer_cloud import ConversationV1\nconversation = ConversationV1(\n    username=CONVERSATION_USERNAME,\n    password=CONVERSATION_PASSWORD,\n    version= VERSION\n)"
        }, 
        {
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "{\n  \"pagination\": {\n    \"refresh_url\": \"/v1/workspaces/b1f9955f-c7db-4298-90fe-c98a65735832/intents?version=2017-05-26\"\n  },\n  \"intents\": [\n    {\n      \"created\": \"2017-10-04T07:34:35.355Z\",\n      \"updated\": \"2017-10-04T07:43:14.700Z\",\n      \"intent\": \"capabilities\",\n      \"description\": \"capabilities\"\n    },\n    {\n      \"created\": \"2017-10-04T07:34:35.665Z\",\n      \"updated\": \"2017-10-04T07:43:13.334Z\",\n      \"intent\": \"interface_issues\",\n      \"description\": \"interface_issues\"\n    },\n    {\n      \"created\": \"2017-10-04T07:34:35.513Z\",\n      \"updated\": \"2017-10-04T07:43:15.387Z\",\n      \"intent\": \"locate_amenity\",\n      \"description\": \"locate_amenity\"\n    }\n  ]\n}\n", 
                    "name": "stdout"
                }
            ], 
            "cell_type": "code", 
            "execution_count": 10, 
            "source": "# test the API - retrieve intents\nintents = conversation.list_intents(WORKSPACE_ID)\nprint(json.dumps(intents, indent=2))"
        }, 
        {
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "{\n  \"created\": \"2017-10-05T01:39:25.570Z\",\n  \"updated\": \"2017-10-05T01:39:25.570Z\",\n  \"intent\": \"sample\",\n  \"description\": \"This is an example\"\n}\n", 
                    "name": "stdout"
                }
            ], 
            "cell_type": "code", 
            "execution_count": 11, 
            "source": "# test the API - create intents\ncreate = conversation.create_intent(WORKSPACE_ID,'sample','This is an example')\nprint(json.dumps(create, indent=2))"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 12, 
            "source": "#Clear the workspace of all existing intents\nintents = conversation.list_intents(workspace_id=WORKSPACE_ID)['intents']\nfor intent in intents:\n    conversation.delete_intent(workspace_id=WORKSPACE_ID, intent=intent['intent'])"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 13, 
            "source": "# now create intent for each intent in the the training data\nfor intent in set([x for x in train['intent']]):\n    conversation.create_intent(workspace_id=WORKSPACE_ID, intent=intent, description=intent)"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 14, 
            "source": "# now add examples\nfor training_data in [x[1] for x in train[:].iterrows()]:\n    conversation.create_example(workspace_id=WORKSPACE_ID, intent=training_data.intent, text=training_data.example)"
        }, 
        {
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Intent Recognizer Performance: 94.29%\n", 
                    "name": "stdout"
                }
            ], 
            "cell_type": "code", 
            "execution_count": 15, 
            "source": "# now test with the test data\nresults = []\nfor test_data in [x[1] for x in test[:].iterrows()]:\n    try:\n        results.append(1 if conversation.message(workspace_id=WORKSPACE_ID, message_input={\"text\": test_data.example})['intents'][0]['intent'] == test_data.intent else 0)\n    except:\n        results.append(0)\nresults = np.array(results)\n\nprint(\"Intent Recognizer Performance: {:.2%}\".format(np.sum(results) / results.size))"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": null, 
            "source": ""
        }
    ], 
    "nbformat_minor": 1
}